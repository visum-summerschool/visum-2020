{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Networks\n",
    "\n",
    "#### *Nicolas Courty, Rémi Flamary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will see how to use the Wasserstein distance in the process of learning a Generative Adversarial Network (GAN). GAN are powerful objects that provide means of generating new samples from complex, high-dimensional distributions $P_r$ (such as collection of images) by learning a generative network $g_\\theta$, parametrized by $\\theta$, that takes a low-dimensional noise (let's say $d$ dimensional) as input. As such, $P_\\theta = g_\\theta(Z)$, $Z \\sim \\mathcal{N}({\\bf 0}_d, {\\bf I}_{d\\times d})$ should match as close as possible $P_r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to train this generator. In a nutshell, the basic idea is to align the distribution of generated samples to the distribution that we want to match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a seminal work, Goodfellow [1] proposed to learn a generator that produces samples that are indistinguishable from the input distribution sample up to a classifier that tries to distinguish them. This leads to an adversarial approach, where both the generator and the classifier work in competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another class of approach considers minimizing a divergence $\\delta$ between $P_r$ and $P_\\theta$ as a loss function for training $g_\\theta$. Several options exist for $\\delta$, for example:\n",
    "* Total Variation, $\\delta(P_r,P_\\theta) = \\sup_{A} | P_r(A) - P_\\theta(A) |$\n",
    "* Kullback-Leibler (KL) divergence, $\\delta(P_r,P_\\theta) = KL(P_r\\|P_\\theta) = \\int_x \\log\\left(\\frac{P_r(x)}{P_\\theta(x)}\\right) P_r(x) \\,dx$\n",
    "\n",
    "Arjovsky and colleagues [2] proposed to use the Wasserstein 1 distance in this context. We have here:\n",
    "$$ \\delta(P_r,P_\\theta) = W_1(P_r,P_\\theta) = \\inf_{\\gamma \\in \\Pi(P_r ,P_\\theta)} \\mathbb{E}_{(x, y) \\sim \\gamma}\\big[\\:\\|x - y\\|\\:\\big] $$\n",
    "\n",
    "There are several nice properties associated with this:\n",
    "* the resulting model is very easy to implement and simple;\n",
    "* the gradients of $W_1$ are practically never 0, which can be the case with Total Variation or KL divergence, especially when the supports of $P_r$ and $P_\\theta$ do not overlap.\n",
    "\n",
    "However, computing $W_1$ requires to compute a coupling $\\gamma$ which is infeasible for large datasets. Instead, relying on the Kantorovich-Rubinstein duality, one can instead consider the dual formulation of $W_1$:\n",
    "$$W(P_r, P_\\theta) = \\sup_{\\|f\\|_L \\leq 1} \\mathbb{E}_{x \\sim P_r}[f(x)] - \\mathbb{E}_{x \\sim P_\\theta}[f(x)]$$\n",
    "where the supremum is taken over all $1-$Lipschitz functions.\n",
    "\n",
    "We are going to explore, how in a task of generating a simple 2D toy distribution, how to implement such a generative adversarial network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "[1] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2 (NIPS'14), Vol. 2. MIT Press, Cambridge, MA, USA, 2672-2680. \n",
    "\n",
    "[2]  Martin Arjovsky, Soumith Chintala, Léon Bottou. 2017, Wasserstein Generative Adversarial Networks. Proceedings of the 34th International Conference on Machine Learning, PMLR 70:214-223, 2017\n",
    "\n",
    "The paper can be found here: http://proceedings.mlr.press/v70/arjovsky17a/arjovsky17a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Generating the data\n",
    "\n",
    "We start by generating a simple circle-like 2D distributions that we will try to approximate through our GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "nb_samples = 10000\n",
    "\n",
    "radius = 1 \n",
    "\n",
    "nz =.1\n",
    "\n",
    "# generate the data\n",
    "X_train = np.zeros((nb_samples,2))\n",
    "r = np.random.normal(radius,nz,nb_samples)\n",
    "theta=np.random.rand(nb_samples)*2*np.pi\n",
    "X_train[:,0]=r*np.cos(theta)\n",
    "X_train[:,1]=r*np.sin(theta)\n",
    "\n",
    "\n",
    "\n",
    "pl.figure(figsize=(6,6))\n",
    "pl.scatter(X_train[:,0], X_train[:,1],s = 20, alpha=0.8, edgecolor = 'k', marker = 'o',label='original samples') \n",
    "pl.xticks([], [])\n",
    "pl.yticks([], [])\n",
    "pl.legend(loc='best')\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Keras implementation of WGAN\n",
    "\n",
    "To implement our GAN model, we will use the Keras toolbox, with Theano or Tensorflow as backend. If it is not installed on your machine, please install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next lines to install Keras and Tensorflow, from: https://www.tensorflow.org/install\n",
    "# Requires the latest pip\n",
    "# !pip install --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is included in Tensorflow 2.0\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating our generator $g_\\theta(Z)$. It consists of a neural network that will take a $d-$dimensional noise vector and produce a sample in 2D.\n",
    "\n",
    "I suggest the following 2-layers architecture, where the non-linearity is produced by using the ReLu activation. The final layer has Linear activations so that the 2D coordinates can be arbitrarily positive or/and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(noise_dim=100):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128,  kernel_initializer='he_normal', input_dim=noise_dim))\n",
    "    model.add(Activation('relu'))      \n",
    "    model.add(Dense(64,  kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))      \n",
    "    model.add(Dense(units=2, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step is a network, usually called *discriminator* in the literature, that is the dual function $f()$ in the previous definition (Kantorovich potential). This function, as a potential function, outputs a scalar value.\n",
    "\n",
    "Please note that this is where the first approximation comes into play. Because $f()$ belongs to a particular class of parameterized neural network, we are not any more optimizing over the set of all $1-$Lipschitz functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, kernel_initializer='he_normal', input_dim=2))\n",
    "    model.add(Activation('relu'))      \n",
    "    model.add(Dense(64, kernel_initializer='he_normal', input_dim=2))\n",
    "    model.add(Activation('relu'))      \n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have both our generator and discriminator. We will construct two of them. We will use a noise dimension of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=2\n",
    "\n",
    "generator = make_generator(noise_dim)\n",
    "discriminator = make_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall here that we want to miminize the Wasserstein distance between the nominal distribution $P_r$ and the generated distribution $P_\\theta$. This leads to the following optimization problem:\n",
    "$$ \\min_\\theta W_1(P_r,P_\\theta) = \\min_\\theta \\sup_{f, ||f||_L=1} \\mathbb{E}_{x \\sim P_r}[f(x)] - \\mathbb{E}_{z \\sim \\mathcal{N}}[f(g_\\theta(z))]$$\n",
    "In order to find $g_\\theta()$, this bi-level optimization problem has to be solved. Generally, one first optimizes over $f()$ with a fixed generator, and, after fixing $f()$, simply maximizes   $\\mathbb{E}_{z \\sim \\mathcal{N}}[f(g_\\theta(z))]$ by backpropagating the gradient of $f()$ in $g_\\theta$.\n",
    "\n",
    "We will first express the two expectations as a simple loss function that simply computes the expectations of $f()$ over $P_r$ and over $P_\\theta$.\n",
    "To take into account the plus and minus signs inside, we simply use a scalar product with a vector of ones or minus ones.\n",
    "Write this corresponding loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now express the fact that when one optimizes over $f()$, $g_\\theta$ is fixed and vice-versa. The discriminator weights are frozen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we connect the generator and the discriminator to get the full generator model that will be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = Input(shape=(noise_dim,))\n",
    "generator_layers = generator(generator_input)\n",
    "discriminator_layers_for_generator = discriminator(generator_layers)\n",
    "generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile it, together with the Adam optimizer as used in the original papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can express the total discriminator model by freezing the generator layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in discriminator.layers:\n",
    "    layer.trainable = True\n",
    "for layer in generator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = True\n",
    "generator.trainable = False\n",
    "\n",
    "real_samples = Input(shape=X_train.shape[1:])\n",
    "generator_input_for_discriminator = Input(shape=(noise_dim,))\n",
    "generated_samples_for_discriminator = generator(generator_input_for_discriminator)\n",
    "discriminator_output_from_generator = discriminator(generated_samples_for_discriminator)\n",
    "discriminator_output_from_real_samples = discriminator(real_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the model outputs values for both real and generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator],\n",
    "                            outputs=[discriminator_output_from_real_samples,\n",
    "                                     discriminator_output_from_generator])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we finally compile it with the two expectation losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model.compile(optimizer=Adam(0.001, beta_1=0.5, beta_2=0.9),\n",
    "                            loss=[wasserstein_loss,wasserstein_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lipschitz constant and neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we replace the supremum over $1-$Lipschitz functions\n",
    "with the supremum over $K-$Lipschitz functions, then the supremum is $K \\cdot W(P_r, P_\\theta)$ instead. This is true because every $K-$Lipschitz function is a $1-$Lipschitz function if you divide it by $K$, and the Wasserstein objective is linear.\n",
    "\n",
    "The supremum over $K-$Lipschitz functions $\\{f : \\|f\\|_L \\le K\\}$ is still intractable, but now it’s easier to approximate.\n",
    "Suppose we have a parametrized function family $\\{f_w\\}_{w \\in \\mathcal{W}}$,\n",
    "where $w$ are the weights and $\\mathcal{W}$ is the set of all possible weights. Further, suppose these functions are all\n",
    "$K-$Lipschitz for some $K$. Then we have\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\max_{w \\in \\mathcal{W}}\n",
    "        \\mathbb{E}_{x \\sim P_r}[f_w(x)] - \\mathbb{E}_{x \\sim P_\\theta}[f_w(x)]\n",
    "    &\\le \\sup_{\\|f\\|_L \\le K}\n",
    "        \\mathbb{E}_{x \\sim P_r}[f(x)] - \\mathbb{E}_{x \\sim P_\\theta}[f(x)] \\\\\n",
    "    &= K \\cdot W(P_r, P_\\theta)\n",
    "\\end{aligned}$$\n",
    "\n",
    "We only care about the gradients of $ W(P_r, P_\\theta)$, so adding multiplying it by a constant $K$ does not change anything. To guarantee that \n",
    "$f_w$ is $K-$Lipschitz, the original WGAN paper proposes to use weight clipping. The weights $w$ are constrained to lie within $[-c, c]$,\n",
    "by clipping $w$ after every update to $w$. \n",
    "\n",
    "Write a function that performs this clipping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_clip(f,c):\n",
    "    for l in f.layers:\n",
    "        weights = l.get_weights()\n",
    "        weights = [np.clip(w, -c, c) for w in weights]\n",
    "        l.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the full model\n",
    "\n",
    "Before running the full model, we provide a function that will help in visualizing the generated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator_model,noise_dim, num_samples=1000):\n",
    "    predicted_samples = generator_model.predict(np.random.rand(num_samples, noise_dim))\n",
    "    pl.figure(figsize=(6,6))\n",
    "    pl.scatter(X_train[:,0], X_train[:,1],s = 40, alpha=0.2, edgecolor = 'k', marker = '+',label='original samples') \n",
    "    pl.scatter(predicted_samples[:,0], predicted_samples[:,1],s = 10, alpha=0.9,c='r', edgecolor = 'k', marker = 'o',label='predicted') \n",
    "    pl.xticks([], [])\n",
    "    pl.yticks([], [])\n",
    "    pl.legend(loc='best')\n",
    "    pl.tight_layout()    \n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now time to run the full model. In theory, one should wait for the full convergence of $f$ before updating $g_\\theta$, but in practice, it can be done after a few iterations over $f$ (another layer of approximation here!). We, therefore, define a training ratio, which basically states the number of discriminator updates per generator update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "TRAINING_RATIO = 5  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write the final loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "\n",
    "for epoch in range(500):\n",
    "    np.random.shuffle(X_train)\n",
    "\n",
    "    minibatches_size = BATCH_SIZE * TRAINING_RATIO\n",
    "    \n",
    "    for i in range(int(X_train.shape[0] // (BATCH_SIZE * TRAINING_RATIO))):\n",
    "        discriminator_minibatches = X_train[i * minibatches_size:(i + 1) * minibatches_size]\n",
    "        for j in range(TRAINING_RATIO):\n",
    "            discriminator_clip(discriminator_model,0.3) # 0.3 is a good value for our toy example\n",
    "            sample_batch = discriminator_minibatches[j * BATCH_SIZE:(j + 1) * BATCH_SIZE]\n",
    "            \n",
    "            # we sample the noise\n",
    "            noise = np.random.rand(BATCH_SIZE, noise_dim).astype(np.float32)\n",
    "            \n",
    "            # and we train on batches the discrimnator\n",
    "            discriminator_model.train_on_batch([sample_batch, noise],[positive_y, negative_y])\n",
    "        \n",
    "        # then we train the generator after TRAINING_RATIO updates\n",
    "        generator_model.train_on_batch(np.random.rand(BATCH_SIZE, noise_dim), positive_y)\n",
    "        \n",
    "    #Visualization of intermediate results\n",
    "    if epoch%50==0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "        generate_images(generator, noise_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play with the different parameters of the code to see how making this GAN converge is nonetheless a fragile thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieving the $K-$Lipschitz condition with weight clipping is a trick that might suffer from some drawbacks, such as poor convergence or poor quality of generated samples, mostly because of underuse of the capacity of the network. In [3], Gulrajani and colleagues proposed a different way of achieving the Lipschitz constraint of $f$ by constraining the norm of the gradient of $f$ to be $1$. The corresponding approximation then reads:\n",
    "\n",
    "$$ \\min_\\theta W_1(P_r,P_\\theta) \\approx \\min_\\theta \\max_w \\mathbb{E}_{x \\sim P_r}[f_w(x)] - \\mathbb{E}_{z \\sim \\mathcal{N}}[f_w(g_\\theta(z))] + \\lambda \\mathbb{E}_{\\hat{x} \\sim P_\\hat{x}}[||\\nabla_\\hat{x} f(\\hat{x})||_2 - 1)^2], $$\n",
    "\n",
    "where $ P_\\hat{x} $ is defined implicitly by sampling uniformly along straight lines between\n",
    "pairs of points sampled from the data distribution $P_r$ and and the generator distribution\n",
    "$P_\\theta$. Practically, this means that we will have to:\n",
    "* construct weighted averages between \n",
    "  $x_1 \\sim P_r$ and $x_2 \\sim P_\\theta$ such that $\\hat{x} = (1-\\epsilon)x_1 + \\epsilon x_2$ with\n",
    "  $\\epsilon \\sim \\mathcal{U}(0,1)$;\n",
    "* evaluate the gradient of $f$ on those points;\n",
    "* define a new loss that constraint this gradient to be close to $1$ when learning for $f$.\n",
    "\n",
    "\n",
    "[3] Gulrajani, Ishaan & Ahmed, Faruk & Arjovsky, Martin & Dumoulin, Vincent & Courville, Aaron. (2017). Improved Training of Wasserstein GANs. \n",
    "https://arxiv.org/pdf/1704.00028.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient penalty loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the gradient penalty loss function, that takes as parameters a batch of points $\\hat{x}$, and the $\\lambda$ parametrizing the strength of this regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples, lamba_reg):\n",
    "    gradients = tf.gradients(y_pred, averaged_samples)[0]\n",
    "    \n",
    "    # Small trick to avoid None values\n",
    "    try:\n",
    "        gradients_sqr = K.square(gradients)\n",
    "    except:\n",
    "        gradients_sqr = tf.zeros(y_pred.shape)\n",
    "        \n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = lamba_reg * K.square(1 - gradient_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolation between samples will be realized by a specific ```keras``` (merge) layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n",
    "\n",
    "class RandomWeightedAverage(Concatenate):\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_uniform((BATCH_SIZE, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator network is now a little bit more complicated since it needs to output its value for the generated samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by building new models\n",
    "\n",
    "generator = make_generator(noise_dim)\n",
    "discriminator = make_discriminator()\n",
    "\n",
    "#### for the generator it is mostly the same as before\n",
    "\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = False\n",
    "\n",
    "generator_input = Input(shape=(noise_dim,))\n",
    "generator_layers = generator(generator_input)\n",
    "discriminator_layers_for_generator = discriminator(generator_layers)\n",
    "generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])\n",
    "\n",
    "generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)\n",
    "\n",
    "#### New discriminator model \n",
    "\n",
    "for layer in discriminator.layers:\n",
    "    layer.trainable = True\n",
    "for layer in generator.layers:\n",
    "    layer.trainable = False\n",
    "discriminator.trainable = True\n",
    "generator.trainable = False\n",
    "\n",
    "real_samples = Input(shape=X_train.shape[1:])\n",
    "generator_input_for_discriminator = Input(shape=(noise_dim,))\n",
    "generated_samples_for_discriminator = generator(generator_input_for_discriminator)\n",
    "discriminator_output_from_generator = discriminator(generated_samples_for_discriminator)\n",
    "discriminator_output_from_real_samples = discriminator(real_samples)\n",
    "\n",
    "averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
    "averaged_samples_out = discriminator(averaged_samples)\n",
    "\n",
    "discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator],\n",
    "                            outputs=[discriminator_output_from_real_samples,\n",
    "                                     discriminator_output_from_generator,\n",
    "                                     averaged_samples_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function takes more inputs than the standard ```y_true``` and ```y_pred``` values usually required for a loss function. We will make it a partial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "GRADIENT_PENALTY_WEIGHT = 1\n",
    "\n",
    "partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                          averaged_samples=averaged_samples,\n",
    "                          lamba_reg=GRADIENT_PENALTY_WEIGHT)\n",
    "partial_gp_loss.__name__ = 'gp_loss' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_model.compile(optimizer=Adam(0.001, beta_1=0.5, beta_2=0.9),\n",
    "                            loss=[wasserstein_loss,\n",
    "                                  wasserstein_loss,\n",
    "                                  partial_gp_loss])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need now this dummy vector mandatory for the train on batch function (even though we do not need it)\n",
    "K.clear_session()\n",
    "\n",
    "# generate the data again\n",
    "X_train = np.zeros((nb_samples,2))\n",
    "r = np.random.normal(radius,nz,nb_samples)\n",
    "theta=np.random.rand(nb_samples)*2*np.pi\n",
    "X_train[:,0]=r*np.cos(theta)\n",
    "X_train[:,1]=r*np.sin(theta)\n",
    "\n",
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "noise_dim=2\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    np.random.shuffle(X_train)\n",
    "\n",
    "    minibatches_size = BATCH_SIZE * TRAINING_RATIO\n",
    "    for i in range(int(X_train.shape[0] // (BATCH_SIZE * TRAINING_RATIO))):\n",
    "        discriminator_minibatches = X_train[i * minibatches_size:(i + 1) * minibatches_size]\n",
    "        for j in range(TRAINING_RATIO):\n",
    "            sample_batch = discriminator_minibatches[j * BATCH_SIZE:(j + 1) * BATCH_SIZE]\n",
    "            noise = np.random.rand(BATCH_SIZE, noise_dim).astype(np.float32)\n",
    "            \n",
    "            discriminator_model.train_on_batch([sample_batch, noise],   [positive_y, negative_y, dummy_y])\n",
    "        \n",
    "        generator_model.train_on_batch(np.random.rand(BATCH_SIZE, noise_dim), positive_y)\n",
    "        \n",
    "    if epoch%50==0:\n",
    "        print(\"Epoch: \", epoch)\n",
    "        generate_images(generator, noise_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, do not hesitate to play with the different parameters so that you get a better idea of the method sensibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
